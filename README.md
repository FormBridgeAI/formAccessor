â™¿ AI-Powered Accessibility Toolkit

This repository contains the research prototype developed during my time as an AI & Accessibility Research Assistant. The project focuses on improving digital accessibility for users with visual and physical impairments using AI-powered tools and human-centered design.

ğŸš€ Overview

This toolkit enhances web accessibility by integrating:
	â€¢	OCR capabilities to extract and read screen content
	â€¢	Multimodal input systems like voice commands and tactile feedback
	â€¢	High-contrast and keyboard-navigable form components
	â€¢	Screen reader optimization following ARIA and WCAG standards

ğŸ§  Key Features
	â€¢	ğŸ” Optical Character Recognition (OCR) using Tesseract.js
	â€¢	ğŸ—£ï¸ Voice Command Support via the Web Speech API
	â€¢	ğŸ›ï¸ Haptics API for tactile feedback
	â€¢	â™¿ Enhanced Form Accessibility with ARIA labeling and keyboard navigation
	â€¢	ğŸ§ª Human-Centered Design Audits using personas and usability heuristics

ğŸ›  Tech Stack
	â€¢	JavaScript / HTML / CSS
	â€¢	Tesseract.js
	â€¢	Web Speech API
	â€¢	NVDA / VoiceOver for screen reader testing
	â€¢	Haptics API
	â€¢	ARIA & WCAG guidelines

ğŸ“ˆ Outcomes
	â€¢	Improved form submission success rates in usability testing
	â€¢	Reduced accessibility failures through iterative audits
	â€¢	Prototyped tools evaluated by users across 3 major assistive technologies

ğŸ“Œ Status

This project is a research prototype. Code is provided as a reference and starting point for future accessibility work. Some features are experimental and not production-ready.
